{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://amunategui.github.io/reinforcement-learning/index.html\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import networkx as nx\n",
    "# starting point is 0 and ending point is 7, point list to visualize graph using networkx library\n",
    "points_list = [(0,1),(0,3),(1,5), (5,6), (5,4), (1,2), (1,3),(2,3), (2,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = 7 #last point to reach from the point 0\n",
    "\n",
    "G=nx.Graph() #graph method of networkx\n",
    "G.add_edges_from(points_list)\n",
    "pos = nx.shell_layout(G) #shape of the graph\n",
    "nx.draw_networkx_nodes(G,pos)\n",
    "nx.draw_networkx_edges(G,pos)\n",
    "nx.draw_networkx_labels(G,pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of point is 8 ( from 0 to 7)\n",
    "MATRIX_SIZE = 8 \n",
    "\n",
    "# create matrix x*y\n",
    "R = np.matrix(np.ones(shape=(MATRIX_SIZE, MATRIX_SIZE)))\n",
    "R *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# assign zeros to paths and 100 to goal-reaching point\n",
    "for point in points_list:\n",
    "    print(point)\n",
    "    if point[1] == goal:\n",
    "        R[point] = 100\n",
    "    else:\n",
    "        R[point] = 0\n",
    "\n",
    "    if point[0] == goal: \n",
    "        R[point[::-1]] = 100\n",
    "    else:\n",
    "        # reverse of point\n",
    "        R[point[::-1]]= 0\n",
    "\n",
    "# add goal point round trip\n",
    "R[goal,goal]= 100 # 2,7 and 7,7 only will get 100\n",
    "\n",
    "R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.matrix(np.zeros([MATRIX_SIZE,MATRIX_SIZE]))\n",
    "\n",
    "# learning parameter\n",
    "gamma = 0.8\n",
    "\n",
    "initial_state = 1\n",
    "\n",
    "def available_actions(state):\n",
    "    current_state_row = R[state,]\n",
    "    av_act = np.where(current_state_row >= 0)[1]\n",
    "    return av_act\n",
    "\n",
    "available_act = available_actions(initial_state) \n",
    "\n",
    "def sample_next_action(available_actions_range):\n",
    "    next_action = int(np.random.choice(available_act,1))\n",
    "    return next_action\n",
    "\n",
    "action = sample_next_action(available_act)\n",
    "\n",
    "def update(current_state, action, gamma):\n",
    "    \n",
    "  max_index = np.where(Q[action,] == np.max(Q[action,]))[1]\n",
    "  \n",
    "  if max_index.shape[0] > 1:\n",
    "      max_index = int(np.random.choice(max_index, size = 1))\n",
    "  else:\n",
    "      max_index = int(max_index)\n",
    "  max_value = Q[action, max_index]\n",
    "  \n",
    "  Q[current_state, action] = R[current_state, action] + gamma * max_value\n",
    "  print('max_value', R[current_state, action] + gamma * max_value)\n",
    "  \n",
    "  if (np.max(Q) > 0):\n",
    "    return(np.sum(Q/np.max(Q)*100))\n",
    "  else:\n",
    "    return (0)\n",
    "print(Q)    \n",
    "update(initial_state, action, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "scores = []\n",
    "for i in range(700):\n",
    "    current_state = np.random.randint(0, int(Q.shape[0]))\n",
    "    available_act = available_actions(current_state)\n",
    "    action = sample_next_action(available_act)\n",
    "    score = update(current_state,action,gamma)\n",
    "    scores.append(score)\n",
    "    print ('Score:', str(score))\n",
    "    \n",
    "print(\"Trained Q matrix:\")\n",
    "print(Q/np.max(Q)*100)\n",
    "\n",
    "# Testing\n",
    "current_state = 0\n",
    "steps = [current_state]\n",
    "\n",
    "while current_state != 7:\n",
    "\n",
    "    next_step_index = np.where(Q[current_state,] == np.max(Q[current_state,]))[1]\n",
    "    \n",
    "    if next_step_index.shape[0] > 1:\n",
    "        next_step_index = int(np.random.choice(next_step_index, size = 1))\n",
    "    else:\n",
    "        next_step_index = int(next_step_index)\n",
    "    \n",
    "    steps.append(next_step_index)\n",
    "    current_state = next_step_index\n",
    "\n",
    "print(\"The most efficient path:\")\n",
    "print(steps)\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
